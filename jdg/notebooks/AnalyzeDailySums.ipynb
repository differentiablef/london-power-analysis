{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfTotal = pd.read_csv(\"../../refined/perfectDailyTotals.csv\")\n",
    "dfAcorn = pd.read_csv(\"../../refined/perfectCustomers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>2013-01-01</th>\n",
       "      <th>2013-01-02</th>\n",
       "      <th>2013-01-03</th>\n",
       "      <th>2013-01-04</th>\n",
       "      <th>2013-01-05</th>\n",
       "      <th>2013-01-06</th>\n",
       "      <th>2013-01-07</th>\n",
       "      <th>2013-01-08</th>\n",
       "      <th>2013-01-09</th>\n",
       "      <th>...</th>\n",
       "      <th>2013-12-22</th>\n",
       "      <th>2013-12-23</th>\n",
       "      <th>2013-12-24</th>\n",
       "      <th>2013-12-25</th>\n",
       "      <th>2013-12-26</th>\n",
       "      <th>2013-12-27</th>\n",
       "      <th>2013-12-28</th>\n",
       "      <th>2013-12-29</th>\n",
       "      <th>2013-12-30</th>\n",
       "      <th>2013-12-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>10.800</td>\n",
       "      <td>13.300</td>\n",
       "      <td>10.074</td>\n",
       "      <td>9.857</td>\n",
       "      <td>11.171</td>\n",
       "      <td>10.293</td>\n",
       "      <td>9.439000</td>\n",
       "      <td>11.640000</td>\n",
       "      <td>15.259</td>\n",
       "      <td>...</td>\n",
       "      <td>12.025</td>\n",
       "      <td>6.721</td>\n",
       "      <td>4.692</td>\n",
       "      <td>4.573</td>\n",
       "      <td>4.590</td>\n",
       "      <td>9.031</td>\n",
       "      <td>13.535</td>\n",
       "      <td>14.876</td>\n",
       "      <td>13.924</td>\n",
       "      <td>13.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>1.854000</td>\n",
       "      <td>3.184</td>\n",
       "      <td>...</td>\n",
       "      <td>3.865</td>\n",
       "      <td>3.815</td>\n",
       "      <td>4.306</td>\n",
       "      <td>4.932</td>\n",
       "      <td>3.864</td>\n",
       "      <td>3.398</td>\n",
       "      <td>2.887</td>\n",
       "      <td>3.047</td>\n",
       "      <td>3.862</td>\n",
       "      <td>3.261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>32.330</td>\n",
       "      <td>32.559</td>\n",
       "      <td>30.772</td>\n",
       "      <td>33.313</td>\n",
       "      <td>30.310</td>\n",
       "      <td>35.150</td>\n",
       "      <td>37.274002</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>32.796</td>\n",
       "      <td>...</td>\n",
       "      <td>35.666</td>\n",
       "      <td>34.399</td>\n",
       "      <td>47.192</td>\n",
       "      <td>64.189</td>\n",
       "      <td>41.526</td>\n",
       "      <td>46.156</td>\n",
       "      <td>45.916</td>\n",
       "      <td>38.192</td>\n",
       "      <td>41.568</td>\n",
       "      <td>37.697998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>11.789</td>\n",
       "      <td>14.018</td>\n",
       "      <td>14.675</td>\n",
       "      <td>17.501</td>\n",
       "      <td>15.830</td>\n",
       "      <td>22.351</td>\n",
       "      <td>17.674000</td>\n",
       "      <td>16.769001</td>\n",
       "      <td>10.459</td>\n",
       "      <td>...</td>\n",
       "      <td>9.037</td>\n",
       "      <td>9.085</td>\n",
       "      <td>8.911</td>\n",
       "      <td>8.908</td>\n",
       "      <td>13.687</td>\n",
       "      <td>12.605</td>\n",
       "      <td>11.750</td>\n",
       "      <td>14.956</td>\n",
       "      <td>14.143</td>\n",
       "      <td>9.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>8.924</td>\n",
       "      <td>8.421</td>\n",
       "      <td>7.818</td>\n",
       "      <td>7.549</td>\n",
       "      <td>6.720</td>\n",
       "      <td>7.826</td>\n",
       "      <td>7.790000</td>\n",
       "      <td>9.333000</td>\n",
       "      <td>8.195</td>\n",
       "      <td>...</td>\n",
       "      <td>8.310</td>\n",
       "      <td>6.925</td>\n",
       "      <td>4.219</td>\n",
       "      <td>4.069</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.675</td>\n",
       "      <td>8.111</td>\n",
       "      <td>8.894</td>\n",
       "      <td>7.193</td>\n",
       "      <td>8.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  2013-01-01  2013-01-02  2013-01-03  2013-01-04  2013-01-05  2013-01-06  \\\n",
       "0   2      10.800      13.300      10.074       9.857      11.171      10.293   \n",
       "1   6       0.500       0.496       0.494       0.495       0.499       0.498   \n",
       "2  10      32.330      32.559      30.772      33.313      30.310      35.150   \n",
       "3  18      11.789      14.018      14.675      17.501      15.830      22.351   \n",
       "4  19       8.924       8.421       7.818       7.549       6.720       7.826   \n",
       "\n",
       "   2013-01-07  2013-01-08  2013-01-09  ...  2013-12-22  2013-12-23  \\\n",
       "0    9.439000   11.640000      15.259  ...      12.025       6.721   \n",
       "1    0.489000    1.854000       3.184  ...       3.865       3.815   \n",
       "2   37.274002   37.500000      32.796  ...      35.666      34.399   \n",
       "3   17.674000   16.769001      10.459  ...       9.037       9.085   \n",
       "4    7.790000    9.333000       8.195  ...       8.310       6.925   \n",
       "\n",
       "   2013-12-24  2013-12-25  2013-12-26  2013-12-27  2013-12-28  2013-12-29  \\\n",
       "0       4.692       4.573       4.590       9.031      13.535      14.876   \n",
       "1       4.306       4.932       3.864       3.398       2.887       3.047   \n",
       "2      47.192      64.189      41.526      46.156      45.916      38.192   \n",
       "3       8.911       8.908      13.687      12.605      11.750      14.956   \n",
       "4       4.219       4.069       4.000       3.675       8.111       8.894   \n",
       "\n",
       "   2013-12-30  2013-12-31  \n",
       "0      13.924   13.415000  \n",
       "1       3.862    3.261000  \n",
       "2      41.568   37.697998  \n",
       "3      14.143    9.387000  \n",
       "4       7.193    8.410000  \n",
       "\n",
       "[5 rows x 366 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTotal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfTotal.drop(columns = ['id'])\n",
    "y = (dfAcorn['acorn-grouped'] == 'Affluent').astype(int).values\n",
    "z = dfAcorn['acorn-grouped']\n",
    "\n",
    "target_names = [\"Non-Affluent\", \"Affluent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train-test split.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Default split ratio is test = 0.25, train = 0.75.\n",
    "# The stratify=z ensures that we have pro-rata sampling from each acorn-group.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=31, stratify=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]0.996969696969697\n",
      "Counter({0: 658, 1: 2})\n",
      "Train accuracy =  0.996969696969697\n",
      "Test accuracy  =  0.5701357466063348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.64      0.66      0.65       133\n",
      "    Affluent       0.46      0.43      0.44        88\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       221\n",
      "   macro avg       0.55      0.55      0.55       221\n",
      "weighted avg       0.57      0.57      0.57       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C=1, verbose=3, loss='hinge',  max_iter = 500000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_train)\n",
    "print(Counter(y_train-predictions)[0] / len(predictions))\n",
    "print(Counter(y_train-predictions))\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "print(\"Train accuracy = \", Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Test accuracy  = \", Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]0.9984848484848485\n",
      "Counter({0: 659, 1: 1})\n",
      "Train accuracy =  0.9984848484848485\n",
      "Test accuracy  =  0.5565610859728507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.63      0.65      0.64       133\n",
      "    Affluent       0.44      0.42      0.43        88\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       221\n",
      "   macro avg       0.53      0.53      0.53       221\n",
      "weighted avg       0.55      0.56      0.55       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C=1, verbose=3, max_iter = 500000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_train)\n",
    "print(Counter(y_train-predictions)[0] / len(predictions))\n",
    "print(Counter(y_train-predictions))\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "print(\"Train accuracy = \", Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Test accuracy  = \", Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]0.9984848484848485\n",
      "Counter({0: 659, 1: 1})\n",
      "Train accuracy =  0.9984848484848485\n",
      "Test accuracy  =  0.5520361990950227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.62      0.65      0.63       133\n",
      "    Affluent       0.43      0.41      0.42        88\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       221\n",
      "   macro avg       0.53      0.53      0.53       221\n",
      "weighted avg       0.55      0.55      0.55       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C=2, verbose=3, max_iter = 500000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_train)\n",
    "print(Counter(y_train-predictions)[0] / len(predictions))\n",
    "print(Counter(y_train-predictions))\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "print(\"Train accuracy = \", Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Test accuracy  = \", Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]0.9984848484848485\n",
      "Counter({0: 659, 1: 1})\n",
      "Train accuracy =  0.9984848484848485\n",
      "Test accuracy  =  0.5656108597285068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.64      0.65      0.64       133\n",
      "    Affluent       0.45      0.44      0.45        88\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       221\n",
      "   macro avg       0.55      0.54      0.55       221\n",
      "weighted avg       0.56      0.57      0.56       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C=2, verbose=3, loss='hinge', max_iter = 500000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_train)\n",
    "print(Counter(y_train-predictions)[0] / len(predictions))\n",
    "print(Counter(y_train-predictions))\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "print(\"Train accuracy = \", Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Test accuracy  = \", Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]0.9984848484848485\n",
      "Counter({0: 659, 1: 1})\n",
      "Train accuracy =  0.9984848484848485\n",
      "Test accuracy  =  0.5701357466063348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.64      0.67      0.65       133\n",
      "    Affluent       0.46      0.42      0.44        88\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       221\n",
      "   macro avg       0.55      0.54      0.54       221\n",
      "weighted avg       0.56      0.57      0.57       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C=3, verbose=3, max_iter = 500000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_train)\n",
    "print(Counter(y_train-predictions)[0] / len(predictions))\n",
    "print(Counter(y_train-predictions))\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "print(\"Train accuracy = \", Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Test accuracy  = \", Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]0.9984848484848485\n",
      "Counter({0: 659, 1: 1})\n",
      "Train accuracy =  0.9984848484848485\n",
      "Test accuracy  =  0.5882352941176471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.65      0.68      0.67       133\n",
      "    Affluent       0.48      0.44      0.46        88\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       221\n",
      "   macro avg       0.57      0.56      0.56       221\n",
      "weighted avg       0.58      0.59      0.58       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C=5, verbose=3, max_iter = 500000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_train)\n",
    "print(Counter(y_train-predictions)[0] / len(predictions))\n",
    "print(Counter(y_train-predictions))\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "print(\"Train accuracy = \", Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Test accuracy  = \", Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]1.0\n",
      "Counter({0: 660})\n",
      "Train accuracy =  1.0\n",
      "Test accuracy  =  0.5882352941176471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.65      0.69      0.67       133\n",
      "    Affluent       0.48      0.43      0.46        88\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       221\n",
      "   macro avg       0.56      0.56      0.56       221\n",
      "weighted avg       0.58      0.59      0.58       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C=10, verbose=3, max_iter = 500000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_train)\n",
    "print(Counter(y_train-predictions)[0] / len(predictions))\n",
    "print(Counter(y_train-predictions))\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "print(\"Train accuracy = \", Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Test accuracy  = \", Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]1.0\n",
      "Counter({0: 660})\n",
      "Train accuracy =  1.0\n",
      "Test accuracy  =  0.5701357466063348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.64      0.65      0.65       133\n",
      "    Affluent       0.46      0.44      0.45        88\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       221\n",
      "   macro avg       0.55      0.55      0.55       221\n",
      "weighted avg       0.57      0.57      0.57       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C=20, verbose=3, max_iter = 500000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_train)\n",
    "print(Counter(y_train-predictions)[0] / len(predictions))\n",
    "print(Counter(y_train-predictions))\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "print(\"Train accuracy = \", Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Test accuracy  = \", Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.9484848484848485\n",
      "Counter({0: 626, 1: 33, -1: 1})\n",
      "Train accuracy =  0.9484848484848485\n",
      "Test accuracy  =  0.5882352941176471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.60      0.98      0.74       133\n",
      "    Affluent       0.00      0.00      0.00        88\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       221\n",
      "   macro avg       0.30      0.49      0.37       221\n",
      "weighted avg       0.36      0.59      0.45       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel = 'rbf', C=1, gamma = 0.001, verbose=3, max_iter = 500000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_train)\n",
    "print(Counter(y_train-predictions)[0] / len(predictions))\n",
    "print(Counter(y_train-predictions))\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "print(\"Train accuracy = \", Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Test accuracy  = \", Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   13.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.0001}\n",
      "[LibSVM] .. Done\n",
      "Train accuracy =  0.7666666666666667\n",
      "Test accuracy  =  0.6742081447963801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.66      0.92      0.77       133\n",
      "    Affluent       0.72      0.30      0.42        88\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       221\n",
      "   macro avg       0.69      0.61      0.60       221\n",
      "weighted avg       0.69      0.67      0.63       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 5, 10, 50], 'gamma': [0.0001, 0.0005, 0.001, 0.002, 0.005]}\n",
    "\n",
    "from trial import rbfTrial\n",
    "\n",
    "rbfTrial(param_grid, target_names, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 560 out of 560 | elapsed:  8.7min finished\n",
      "C:\\Users\\jgree\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'degree': 4, 'gamma': 0.0001}\n",
      "[LibSVM] .. Done\n",
      "Train accuracy =  0.906060606060606\n",
      "Test accuracy  =  0.665158371040724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.69      0.82      0.75       133\n",
      "    Affluent       0.61      0.43      0.51        88\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       221\n",
      "   macro avg       0.65      0.63      0.63       221\n",
      "weighted avg       0.66      0.67      0.65       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 5, 10, 50], 'gamma': [0.0001, 0.0005, 0.001, 0.005], 'degree': [4,5,6,7,8,9,10]}\n",
    "\n",
    "from trial import polyTrial\n",
    "\n",
    "polyTrial(param_grid, target_names, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   53.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.0001}\n",
      "[LibSVM] .. Done\n",
      "Train accuracy =  0.7666666666666667\n",
      "Test accuracy  =  0.6742081447963801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.66      0.92      0.77       133\n",
      "    Affluent       0.72      0.30      0.42        88\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       221\n",
      "   macro avg       0.69      0.61      0.60       221\n",
      "weighted avg       0.69      0.67      0.63       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 5, 10, 50], 'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "\n",
    "from trial import linearTrial\n",
    "\n",
    "linearTrial(param_grid, target_names, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgree\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " .. Done\n",
      "Train accuracy =  0.9878787878787879\n",
      "Test accuracy  =  0.5882352941176471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.60      0.98      0.74       133\n",
      "    Affluent       0.00      0.00      0.00        88\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       221\n",
      "   macro avg       0.30      0.49      0.37       221\n",
      "weighted avg       0.36      0.59      0.45       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 2, 5, 10, 20, 50] }\n",
    "\n",
    "from trial import linearSVCTrial\n",
    "\n",
    "linearSVCTrial(param_grid, target_names, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.0001}\n",
      "[LibSVM]0.9424242424242424\n",
      "Counter({0: 622, 1: 37, -1: 1})\n",
      "Train accuracy =  0.9424242424242424\n",
      "Test accuracy  =  0.665158371040724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.69      0.81      0.74       133\n",
      "    Affluent       0.61      0.44      0.51        88\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       221\n",
      "   macro avg       0.65      0.63      0.63       221\n",
      "weighted avg       0.66      0.67      0.65       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 5, 10, 50], 'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "model = SVC(kernel = 'rbf')\n",
    "grid = GridSearchCV(model, param_grid, verbose=3, n_jobs=-1, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "model = SVC(verbose=3, kernel = 'rbf', max_iter = 1000000, **grid.best_params_)\n",
    "model.fit(X_train, y_train)\n",
    "    \n",
    "predictions = model.predict(X_train)\n",
    "print(Counter(y_train-predictions)[0] / len(predictions))\n",
    "print(Counter(y_train-predictions))\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "print(\"Train accuracy = \", Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Test accuracy  = \", Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Counter({0: 622, 1: 37, -1: 1})\n",
      "0.9424242424242424\n",
      "Counter({0: 147, 1: 49, -1: 25})\n",
      "0.665158371040724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.69      0.81      0.74       133\n",
      "    Affluent       0.61      0.44      0.51        88\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       221\n",
      "   macro avg       0.65      0.63      0.63       221\n",
      "weighted avg       0.66      0.67      0.65       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(verbose=3, kernel = 'rbf', max_iter = 1000000, **grid.best_params_)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "print(Counter(y_train-predictions))\n",
    "print(Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(Counter(y_test-predictions))\n",
    "print(Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Counter({0: 626, 1: 33, -1: 1})\n",
      "0.9484848484848485\n",
      "Counter({0: 130, 1: 88, -1: 3})\n",
      "0.5882352941176471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.60      0.98      0.74       133\n",
      "    Affluent       0.00      0.00      0.00        88\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       221\n",
      "   macro avg       0.30      0.49      0.37       221\n",
      "weighted avg       0.36      0.59      0.45       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(verbose=3, kernel = 'rbf', max_iter = 1000000, C=1, gamma = 0.001)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "print(Counter(y_train-predictions))\n",
    "print(Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(Counter(y_test-predictions))\n",
    "print(Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Counter({0: 653, 1: 7})\n",
      "0.9893939393939394\n",
      "Counter({0: 122, 1: 50, -1: 49})\n",
      "0.5520361990950227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.63      0.63      0.63       133\n",
      "    Affluent       0.44      0.43      0.43        88\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       221\n",
      "   macro avg       0.53      0.53      0.53       221\n",
      "weighted avg       0.55      0.55      0.55       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(verbose=3, kernel = 'poly', max_iter = 5000000, C=1, gamma = 0.001)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "print(Counter(y_train-predictions))\n",
    "print(Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(Counter(y_test-predictions))\n",
    "print(Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using Scaled Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Counter({0: 399, 1: 261})\n",
      "0.6045454545454545\n",
      "Counter({0: 133, 1: 88})\n",
      "0.6018099547511312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.60      1.00      0.75       133\n",
      "    Affluent       0.00      0.00      0.00        88\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       221\n",
      "   macro avg       0.30      0.50      0.38       221\n",
      "weighted avg       0.36      0.60      0.45       221\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgree\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = SVC(verbose=3, kernel = 'rbf', max_iter = 1000000, C=1, gamma = 0.001)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = model.predict(X_train_scaled)\n",
    "print(Counter(y_train-predictions))\n",
    "print(Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(Counter(y_test-predictions))\n",
    "print(Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Counter({0: 527, 1: 127, -1: 6})\n",
      "0.7984848484848485\n",
      "Counter({0: 151, 1: 55, -1: 15})\n",
      "0.6832579185520362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.68      0.89      0.77       133\n",
      "    Affluent       0.69      0.38      0.49        88\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       221\n",
      "   macro avg       0.68      0.63      0.63       221\n",
      "weighted avg       0.68      0.68      0.66       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C=1, verbose=3, max_iter = 100000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = model.predict(X_train_scaled)\n",
    "print(Counter(y_train-predictions))\n",
    "print(Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(Counter(y_test-predictions))\n",
    "print(Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Counter({0: 590, 1: 58, -1: 12})\n",
      "0.8939393939393939\n",
      "Counter({0: 140, 1: 52, -1: 29})\n",
      "0.6334841628959276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.67      0.78      0.72       133\n",
      "    Affluent       0.55      0.41      0.47        88\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       221\n",
      "   macro avg       0.61      0.60      0.60       221\n",
      "weighted avg       0.62      0.63      0.62       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C=10, verbose=3, max_iter = 100000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = model.predict(X_train_scaled)\n",
    "print(Counter(y_train-predictions))\n",
    "print(Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(Counter(y_test-predictions))\n",
    "print(Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Counter({0: 399, 1: 261})\n",
      "0.6045454545454545\n",
      "Counter({0: 133, 1: 88})\n",
      "0.6018099547511312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.60      1.00      0.75       133\n",
      "    Affluent       0.00      0.00      0.00        88\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       221\n",
      "   macro avg       0.30      0.50      0.38       221\n",
      "weighted avg       0.36      0.60      0.45       221\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgree\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = SVC(verbose=3, kernel = 'rbf', max_iter = 1000000, C=2, gamma = 0.0001)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = model.predict(X_train_scaled)\n",
    "print(Counter(y_train-predictions))\n",
    "print(Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(Counter(y_test-predictions))\n",
    "print(Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Counter({0: 399, 1: 261})\n",
      "0.6045454545454545\n",
      "Counter({0: 133, 1: 88})\n",
      "0.6018099547511312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.60      1.00      0.75       133\n",
      "    Affluent       0.00      0.00      0.00        88\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       221\n",
      "   macro avg       0.30      0.50      0.38       221\n",
      "weighted avg       0.36      0.60      0.45       221\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgree\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = SVC(verbose=3, kernel = 'poly', max_iter = 5000000, C=10, gamma = 0.001, degree = 10)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = model.predict(X_train_scaled)\n",
    "print(Counter(y_train-predictions))\n",
    "print(Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(Counter(y_test-predictions))\n",
    "print(Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Counter({0: 399, 1: 261})\n",
      "0.6045454545454545\n",
      "Counter({0: 133, 1: 88})\n",
      "0.6018099547511312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.60      1.00      0.75       133\n",
      "    Affluent       0.00      0.00      0.00        88\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       221\n",
      "   macro avg       0.30      0.50      0.38       221\n",
      "weighted avg       0.36      0.60      0.45       221\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgree\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = SVC(verbose=3, kernel = 'poly', max_iter = 5000000, C=1, gamma = 0.001)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = model.predict(X_train_scaled)\n",
    "print(Counter(y_train-predictions))\n",
    "print(Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(Counter(y_test-predictions))\n",
    "print(Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Counter({0: 400, 1: 260})\n",
      "0.6060606060606061\n",
      "Counter({0: 134, 1: 87})\n",
      "0.6063348416289592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.60      1.00      0.75       133\n",
      "    Affluent       1.00      0.01      0.02        88\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       221\n",
      "   macro avg       0.80      0.51      0.39       221\n",
      "weighted avg       0.76      0.61      0.46       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(verbose=3, kernel = 'rbf', max_iter = 1000000, C=4, gamma = 0.001)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = model.predict(X_train_scaled)\n",
    "print(Counter(y_train-predictions))\n",
    "print(Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(Counter(y_test-predictions))\n",
    "print(Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Counter({0: 400, 1: 260})\n",
      "0.6060606060606061\n",
      "Counter({0: 134, 1: 87})\n",
      "0.6063348416289592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.60      1.00      0.75       133\n",
      "    Affluent       1.00      0.01      0.02        88\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       221\n",
      "   macro avg       0.80      0.51      0.39       221\n",
      "weighted avg       0.76      0.61      0.46       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(verbose=3, kernel = 'rbf', max_iter = 1000000, C=10, gamma = 0.001)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = model.predict(X_train_scaled)\n",
    "print(Counter(y_train-predictions))\n",
    "print(Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(Counter(y_test-predictions))\n",
    "print(Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.01}\n",
      "[LibSVM]Counter({0: 407, 1: 252, -1: 1})\n",
      "0.6166666666666667\n",
      "Counter({0: 139, 1: 81, -1: 1})\n",
      "0.6289592760180995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.62      0.99      0.76       133\n",
      "    Affluent       0.88      0.08      0.15        88\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       221\n",
      "   macro avg       0.75      0.54      0.45       221\n",
      "weighted avg       0.72      0.63      0.52       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 2, 3], 'gamma': [0.0, 0.00002, 0.00005, 0.00007, 0.0001, 0.0005, 0.001, 0.005, 0.01]}\n",
    "model = SVC(kernel = 'rbf', max_iter = 1000000)\n",
    "grid = GridSearchCV(model, param_grid, verbose=3, n_jobs=-1, cv=3)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "model = SVC(verbose=3, kernel = 'rbf', max_iter = 1000000, **grid.best_params_)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = model.predict(X_train_scaled)\n",
    "print(Counter(y_train-predictions))\n",
    "print(Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(Counter(y_test-predictions))\n",
    "print(Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    7.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 50, 'gamma': 0.01}\n",
      "[LibSVM]Counter({0: 463, 1: 193, -1: 4})\n",
      "0.7015151515151515\n",
      "Counter({0: 146, 1: 72, -1: 3})\n",
      "0.6606334841628959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.64      0.98      0.78       133\n",
      "    Affluent       0.84      0.18      0.30        88\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       221\n",
      "   macro avg       0.74      0.58      0.54       221\n",
      "weighted avg       0.72      0.66      0.59       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 5, 10, 50], 'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]}\n",
    "model = SVC(kernel = 'rbf', max_iter = 1000000)\n",
    "grid = GridSearchCV(model, param_grid, verbose=3, n_jobs=-1, cv=3)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "model = SVC(verbose=3, kernel = 'rbf', max_iter = 1000000, **grid.best_params_)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = model.predict(X_train_scaled)\n",
    "print(Counter(y_train-predictions))\n",
    "print(Counter(y_train-predictions)[0] / sum(Counter(y_train-predictions).values()))\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(Counter(y_test-predictions))\n",
    "print(Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:   21.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 25, 'gamma': 0.05}\n",
      "[LibSVM] .. Done\n",
      "Train accuracy =  0.7681818181818182\n",
      "Test accuracy  =  0.6968325791855203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.68      0.95      0.79       133\n",
      "    Affluent       0.82      0.31      0.45        88\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       221\n",
      "   macro avg       0.75      0.63      0.62       221\n",
      "weighted avg       0.73      0.70      0.65       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at this again.\n",
    "\n",
    "param_grid = {'C': [1, 5, 10, 25, 50, 75, 100], 'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]}\n",
    "\n",
    "from trial import rbfTrial\n",
    "\n",
    "rbfTrial(param_grid, target_names, X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:   27.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.0001}\n",
      "[LibSVM] .. Done\n",
      "Train accuracy =  0.7666666666666667\n",
      "Test accuracy  =  0.6742081447963801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.66      0.92      0.77       133\n",
      "    Affluent       0.72      0.30      0.42        88\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       221\n",
      "   macro avg       0.69      0.61      0.60       221\n",
      "weighted avg       0.69      0.67      0.63       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 5, 10, 25, 50, 75, 100], 'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]}\n",
    "\n",
    "from trial import rbfTrial\n",
    "\n",
    "rbfTrial(param_grid, target_names, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgree\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " .. Done\n",
      "Train accuracy =  0.9878787878787879\n",
      "Test accuracy  =  0.5882352941176471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.60      0.98      0.74       133\n",
      "    Affluent       0.00      0.00      0.00        88\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       221\n",
      "   macro avg       0.30      0.49      0.37       221\n",
      "weighted avg       0.36      0.59      0.45       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 2, 5, 10, 15, 20, 25, 30, 50] }\n",
    "\n",
    "from trial import linearSVCTrial\n",
    "\n",
    "linearSVCTrial(param_grid, target_names, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   39.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2}\n",
      "[LibSVM] .. Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgree\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train accuracy =  0.6045454545454545\n",
      "Test accuracy  =  0.6063348416289592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.60      1.00      0.75       133\n",
      "    Affluent       1.00      0.01      0.02        88\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       221\n",
      "   macro avg       0.80      0.51      0.39       221\n",
      "weighted avg       0.76      0.61      0.46       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 2, 5, 10, 15, 20, 25, 30, 50] }\n",
    "\n",
    "from trial import linearSVCTrial\n",
    "\n",
    "linearSVCTrial(param_grid, target_names, X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 210 out of 210 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.0001}\n",
      "[LibSVM] .. Done\n",
      "Train accuracy =  0.7666666666666667\n",
      "Test accuracy  =  0.6742081447963801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.66      0.92      0.77       133\n",
      "    Affluent       0.72      0.30      0.42        88\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       221\n",
      "   macro avg       0.69      0.61      0.60       221\n",
      "weighted avg       0.69      0.67      0.63       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 5, 10, 20, 25, 40, 50], 'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]}\n",
    "\n",
    "from trial import linearTrial\n",
    "\n",
    "linearTrial(param_grid, target_names, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 210 out of 210 | elapsed:   23.6s finished\n",
      "C:\\Users\\jgree\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'gamma': 0.0001}\n",
      "[LibSVM] .. Done\n",
      "Train accuracy =  0.6045454545454545\n",
      "Test accuracy  =  0.6018099547511312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.60      1.00      0.75       133\n",
      "    Affluent       0.00      0.00      0.00        88\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       221\n",
      "   macro avg       0.30      0.50      0.38       221\n",
      "weighted avg       0.36      0.60      0.45       221\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgree\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 5, 10, 20, 25, 40, 50], 'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]}\n",
    "\n",
    "from trial import linearTrial\n",
    "\n",
    "linearTrial(param_grid, target_names, X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAff = dfAcorn.loc[dfAcorn['acorn-grouped']=='Affluent']\n",
    "dfNonAff = dfAcorn.loc[dfAcorn['acorn-grouped']!='Affluent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349 532\n"
     ]
    }
   ],
   "source": [
    "print(len(dfAff), len(dfNonAff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNonAff = dfNonAff.sample(n = len(dfAff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEqAff = dfAff.append(dfNonAff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEqAff = dfEqAff.sort_values(by=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEqual = pd.merge(dfEqAff['id'], dfTotal, how='left', on = 'id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = dfEqual.drop(columns = ['id'])\n",
    "y2 = (dfEqAff['acorn-grouped'] == 'Affluent').astype(int).values\n",
    "z2 = dfEqAff['acorn-grouped']\n",
    "\n",
    "target_names = [\"Non-Affluent\", \"Affluent\"]\n",
    "\n",
    "# Perform a train-test split.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Default split ratio is test = 0.25, train = 0.75.\n",
    "# The stratify=z ensures that we have pro-rata sampling from each acorn-group.\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, random_state=31, stratify=z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:   19.6s finished\n",
      "C:\\Users\\jgree\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.0001}\n",
      "[LibSVM] .. Done\n",
      "Train accuracy =  0.9579349904397706\n",
      "Test accuracy  =  0.6228571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.62      0.62      0.62        88\n",
      "    Affluent       0.62      0.62      0.62        87\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       175\n",
      "   macro avg       0.62      0.62      0.62       175\n",
      "weighted avg       0.62      0.62      0.62       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 5, 10, 25, 50, 75, 100], 'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]}\n",
    "\n",
    "from trial import rbfTrial\n",
    "\n",
    "rbfTrial(param_grid, target_names, X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done 210 out of 210 | elapsed:   50.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.0001}\n",
      "[LibSVM] .. Done\n",
      "Train accuracy =  0.7705544933078394\n",
      "Test accuracy  =  0.6228571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.59      0.81      0.68        88\n",
      "    Affluent       0.69      0.44      0.54        87\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       175\n",
      "   macro avg       0.64      0.62      0.61       175\n",
      "weighted avg       0.64      0.62      0.61       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 5, 10, 20, 25, 40, 50], 'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]}\n",
    "\n",
    "from trial import linearTrial\n",
    "\n",
    "linearTrial(param_grid, target_names, X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2}\n",
      "[LibSVM] .. Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgree\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy =  1.0\n",
      "Test accuracy  =  0.5828571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.67      0.34      0.45        88\n",
      "    Affluent       0.55      0.83      0.66        87\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       175\n",
      "   macro avg       0.61      0.58      0.56       175\n",
      "weighted avg       0.61      0.58      0.56       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [1, 2, 5, 10, 15, 20, 25, 30, 50] }\n",
    "\n",
    "from trial import linearSVCTrial\n",
    "\n",
    "linearSVCTrial(param_grid, target_names,X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Counter({0: 174, -1: 31, 1: 16})\n",
      "0.7873303167420814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Affluent       0.86      0.77      0.81       133\n",
      "    Affluent       0.70      0.82      0.75        88\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       221\n",
      "   macro avg       0.78      0.79      0.78       221\n",
      "weighted avg       0.80      0.79      0.79       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train using equal number of affluent and non-affluent.\n",
    "# Test using proportions consistent with the original supports.\n",
    "\n",
    "model = LinearSVC(verbose=3,  max_iter = 1000000, C=2)\n",
    "model.fit(X_train2, y_train2)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(Counter(y_test-predictions))\n",
    "print(Counter(y_test-predictions)[0] / sum(Counter(y_test-predictions).values()))\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
